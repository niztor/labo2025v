{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/niztor/labo2025v/blob/main/src/rpart/290_TareaHogar_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tarea para el Hogar 02"
      ],
      "metadata": {
        "id": "F3r8aa3pBigj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta Tarea para el Hogar 02 se entrega el final de la segunda clase\n",
        "<br> se espera de usted que intente avanzar con los desafios propuestos y que los traiga terminados para la Clase 03, ya que se analizarán los resultados"
      ],
      "metadata": {
        "id": "nBm4ktHUBmZt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  1. Ensembles de Modelos"
      ],
      "metadata": {
        "id": "TK-M04ElCESC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vea el siguiente video [BBC - The Code - The Wisdom of the Crowd](https://www.youtube.com/watch?v=iOucwX7Z1HU)    ( 5 min)\n"
      ],
      "metadata": {
        "id": "biPYxgobCOSS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lea los siguientes artículos\n",
        "\n",
        "\n",
        "*   [The Wisdom of Crowds (Vox Populi) by Francis Galton](https://www.all-about-psychology.com/the-wisdom-of-crowds.html)  (10 min)\n",
        "*   [A Gentle Introduction to Ensemble Learning](https://machinelearningmastery.com/what-is-ensemble-learning/)  (10 min)\n",
        "\n"
      ],
      "metadata": {
        "id": "FBszBRyNCcjp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "x7SebtV2lpHQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  2.  Zero2Hero   primera parte\n",
        "Se han lanzado los primeros fascículos coleccionables llamados \"from Zero to Hero\" que muy detalladamente, paso a paso enseñan todo lo necesario de R para entender los scripts oficiales de la asignatura.\n",
        "Están en el repositorio oficial de la asignatura, carpeta  **src/zero2hero**"
      ],
      "metadata": {
        "id": "NQcY8u2MDSLT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "GcO0OSiIEAGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.  Grid Search"
      ],
      "metadata": {
        "id": "6MStcyn0EBdT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Busque en internet el precido significado de los hiperparámetros de la librería **rpart**  que está implementando el algoritmo **CART**  Classification and Regression Trees  propuesto en el año 1984 por Leo Brieman:\n",
        "\n",
        "*   cp\n",
        "*   maxdepth\n",
        "*   minsplit\n",
        "*   minbucket\n",
        "\n",
        "Entienda que valores es razonable tome cada hiperparámetro,  en particular profundice en el hiperparámetro  **cp**  y la posibilidad que tome valores negativos.  Es válido consultar a su amigo de *capacidades especiales*  ChatGPT\n"
      ],
      "metadata": {
        "id": "gM8RKXDgEIY0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En las siguientes celdas a un notebook incompleto, un esqueleto de codigo brindado a modo de facilitarle la tarea de codeo y permitir que su valiosa cognición se concentre temas conceptuales de Ciencia de Datos\n",
        "\n",
        "Modifiquelo agregando loops para que recorra TODOS los hiperparámetros de rpart  < cp, maxdepth, minsplit, minbucket >, y luego póngalo a correr. Recuerde cambiar por SU semilla\n",
        "Tenga muy presente la granularidad que eligirá para cada hiperparámetro."
      ],
      "metadata": {
        "id": "_k7eT3HIFy9y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Seteo del ambiente en Google Colab"
      ],
      "metadata": {
        "id": "kmLygy1TYPfg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta parte se debe correr con el runtime en Python3\n",
        "<br>Ir al menu, Runtime -> Change Runtime Tipe -> Runtime type ->  **Python 3**"
      ],
      "metadata": {
        "id": "OikOm5K2YU3X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conectar la virtual machine donde esta corriendo Google Colab con el  Google Drive, para poder tener persistencia de archivos"
      ],
      "metadata": {
        "id": "4fmV5LyZdFyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# primero establecer el Runtime de Python 3\n",
        "from google.colab import drive\n",
        "drive.mount('/content/.drive')"
      ],
      "metadata": {
        "id": "ilEZ-bE2VybW",
        "outputId": "b4d9292d-0428-4832-de66-902282374a6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/.drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para correr la siguiente celda es fundamental en Arranque en Frio haber copiado el archivo kaggle.json al Google Drive, en la carpeta indicada en el instructivo\n",
        "\n",
        "<br>los siguientes comando estan en shell script de Linux\n",
        "*   Crear las carpetas en el Google Drive\n",
        "*   \"instalar\" el archivo kaggle.json desde el Google Drive a la virtual machine para que pueda ser utilizado por la libreria  kaggle de Python\n",
        "*   Bajar el  **dataset_pequeno**  al  Google Drive  y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
        "\n"
      ],
      "metadata": {
        "id": "ilaKtqWldeWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "mkdir -p \"/content/.drive/My Drive/labo1\"\n",
        "mkdir -p \"/content/buckets\"\n",
        "ln -s \"/content/.drive/My Drive/labo1\" /content/buckets/b1\n",
        "\n",
        "mkdir -p ~/.kaggle\n",
        "cp /content/buckets/b1/kaggle/kaggle.json  ~/.kaggle\n",
        "chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "\n",
        "mkdir -p /content/buckets/b1/exp\n",
        "mkdir -p /content/buckets/b1/datasets\n",
        "mkdir -p /content/datasets\n",
        "\n",
        "\n",
        "\n",
        "archivo_origen=\"https://storage.googleapis.com/open-courses/austral2025-af91/dataset_pequeno.csv\"\n",
        "archivo_destino=\"/content/datasets/dataset_pequeno.csv\"\n",
        "archivo_destino_bucket=\"/content/buckets/b1/datasets/dataset_pequeno.csv\"\n",
        "\n",
        "if ! test -f $archivo_destino_bucket; then\n",
        "  wget  $archivo_origen  -O $archivo_destino_bucket\n",
        "fi\n",
        "\n",
        "\n",
        "if ! test -f $archivo_destino; then\n",
        "  cp  $archivo_destino_bucket  $archivo_destino\n",
        "fi\n",
        "\n"
      ],
      "metadata": {
        "id": "W8dQFI5QYCFa",
        "outputId": "74f0b904-2128-47c8-994e-02dd4896136e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "limpio el ambiente de R"
      ],
      "metadata": {
        "id": "SE94XRhWsxkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# limpio la memoria\n",
        "rm(list=ls(all.names=TRUE)) # remove all objects\n",
        "gc(full=TRUE, verbose=FALSE) # garbage collection"
      ],
      "metadata": {
        "id": "oZG_4br6szlT",
        "outputId": "cef77aa4-01d8-4aa2-e2ee-0472d8cab607",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>Ncells</th><td> 657247</td><td>35.2</td><td>1454462</td><td>77.7</td><td>1367415</td><td>73.1</td></tr>\n",
              "\t<tr><th scope=row>Vcells</th><td>1220276</td><td> 9.4</td><td>8388608</td><td>64.0</td><td>1975128</td><td>15.1</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA matrix: 2 × 6 of type dbl\n\n| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n|---|---|---|---|---|---|---|\n| Ncells |  657247 | 35.2 | 1454462 | 77.7 | 1367415 | 73.1 |\n| Vcells | 1220276 |  9.4 | 8388608 | 64.0 | 1975128 | 15.1 |\n\n",
            "text/latex": "A matrix: 2 × 6 of type dbl\n\\begin{tabular}{r|llllll}\n  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n\\hline\n\tNcells &  657247 & 35.2 & 1454462 & 77.7 & 1367415 & 73.1\\\\\n\tVcells & 1220276 &  9.4 & 8388608 & 64.0 & 1975128 & 15.1\\\\\n\\end{tabular}\n",
            "text/plain": [
              "       used    (Mb) gc trigger (Mb) max used (Mb)\n",
              "Ncells  657247 35.2 1454462    77.7 1367415  73.1\n",
              "Vcells 1220276  9.4 8388608    64.0 1975128  15.1"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cargo las librerias que necesito\n",
        "require(\"data.table\")\n",
        "require(\"rpart\")\n",
        "require(\"parallel\")\n",
        "if (!require(\"primes\")) install.packages(\"primes\")\n",
        "require(\"primes\")"
      ],
      "metadata": {
        "id": "JO-12d7YHkWy",
        "outputId": "a526b0a7-efd6-46eb-f2c6-cc01e1aa5b6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading required package: data.table\n",
            "\n",
            "Loading required package: rpart\n",
            "\n",
            "Loading required package: parallel\n",
            "\n",
            "Loading required package: primes\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘primes’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Loading required package: primes\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui debe poner SU semiila primigenia"
      ],
      "metadata": {
        "id": "0MclPEJ6Q8Bp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PARAM <- list()\n",
        "# reemplazar por su primer semilla\n",
        "PARAM$semilla_primigenia <- 191717\n",
        "PARAM$qsemillas <- 5\n",
        "\n",
        "PARAM$training_pct <- 70L  # entre  1L y 99L\n",
        "\n",
        "# elegir SU dataset comentando/ descomentando\n",
        "PARAM$dataset_nom <- \"~/datasets/dataset_pequeno.csv\""
      ],
      "metadata": {
        "id": "Vt5fC6bWHu5r"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# particionar agrega una columna llamada fold a un dataset\n",
        "#  que consiste en una particion estratificada segun agrupa\n",
        "# particionar( data=dataset, division=c(70,30), agrupa=clase_ternaria, seed=semilla)\n",
        "#   crea una particion 70, 30\n",
        "\n",
        "particionar <- function(data, division, agrupa = \"\", campo = \"fold\", start = 1, seed = NA) {\n",
        "  if (!is.na(seed)) set.seed(seed)\n",
        "\n",
        "  bloque <- unlist(mapply(function(x, y) {\n",
        "    rep(y, x)\n",
        "  }, division, seq(from = start, length.out = length(division))))\n",
        "\n",
        "  data[, (campo) := sample(rep(bloque, ceiling(.N / length(bloque))))[1:.N],\n",
        "    by = agrupa\n",
        "  ]\n",
        "}\n"
      ],
      "metadata": {
        "id": "Z1dchsrWH4MD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ArbolEstimarGanancia <- function(semilla, training_pct, param_basicos) {\n",
        "  # particiono estratificadamente el dataset\n",
        "  particionar(dataset,\n",
        "    division = c(training_pct, 100L -training_pct),\n",
        "    agrupa = \"clase_ternaria\",\n",
        "    seed = semilla # aqui se usa SU semilla\n",
        "  )\n",
        "\n",
        "  # genero el modelo\n",
        "  # predecir clase_ternaria a partir del resto\n",
        "  modelo <- rpart(\"clase_ternaria ~ .\",\n",
        "    data = dataset[fold == 1], # fold==1  es training,  el 70% de los datos\n",
        "    xval = 0,\n",
        "    control = param_basicos\n",
        "  ) # aqui van los parametros del arbol\n",
        "\n",
        "  # aplico el modelo a los datos de testing\n",
        "  prediccion <- predict(modelo, # el modelo que genere recien\n",
        "    dataset[fold == 2], # fold==2  es testing, el 30% de los datos\n",
        "    type = \"prob\"\n",
        "  ) # type= \"prob\"  es que devuelva la probabilidad\n",
        "\n",
        "  # prediccion es una matriz con TRES columnas,\n",
        "  #  llamadas \"BAJA+1\", \"BAJA+2\"  y \"CONTINUA\"\n",
        "  # cada columna es el vector de probabilidades\n",
        "\n",
        "\n",
        "  # calculo la ganancia en testing  qu es fold==2\n",
        "  ganancia_test <- dataset[\n",
        "    fold == 2,\n",
        "    sum(ifelse(prediccion[, \"BAJA+2\"] > 0.025,\n",
        "      ifelse(clase_ternaria == \"BAJA+2\", 117000, -3000),\n",
        "      0\n",
        "    ))\n",
        "  ]\n",
        "\n",
        "  # escalo la ganancia como si fuera todo el dataset\n",
        "  ganancia_test_normalizada <- ganancia_test / (( 100 - PARAM$training_pct ) / 100 )\n",
        "\n",
        "  return(\n",
        "    c( list(\"semilla\" = semilla),\n",
        "      param_basicos,\n",
        "      list( \"ganancia_test\" = ganancia_test_normalizada )\n",
        "     )\n",
        "  )\n",
        "}\n"
      ],
      "metadata": {
        "id": "xsHwS1CzIA70"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ArbolesMontecarlo <- function(semillas, param_basicos) {\n",
        "\n",
        "  # la funcion mcmapply  llama a la funcion ArbolEstimarGanancia\n",
        "  #  tantas veces como valores tenga el vector  PARAM$semillas\n",
        "  salida <- mcmapply(ArbolEstimarGanancia,\n",
        "    semillas, # paso el vector de semillas\n",
        "    MoreArgs = list(PARAM$training_pct, param_basicos), # aqui paso el segundo parametro\n",
        "    SIMPLIFY = FALSE,\n",
        "    mc.cores = detectCores()\n",
        "  )\n",
        "\n",
        "  return(salida)\n",
        "}\n"
      ],
      "metadata": {
        "id": "BvBVOuhqIEjD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# carpeta de trabajo\n",
        "# por fabor cambiar numero de experimento si se cambia el loop principal\n",
        "setwd(\"/content/buckets/b1/exp\")\n",
        "experimento <- \"HT0211_1\"\n",
        "dir.create(experimento, showWarnings=FALSE)\n",
        "setwd( paste0(\"/content/buckets/b1/exp/\", experimento ))"
      ],
      "metadata": {
        "id": "L-DOGHOjIG7G"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lectura del dataset\n",
        "dataset <- fread(\"/content/datasets/dataset_pequeno.csv\")\n",
        "\n",
        "# trabajo solo con los datos con clase, es decir 202107\n",
        "dataset <- dataset[clase_ternaria != \"\"]"
      ],
      "metadata": {
        "id": "NM-mrLWcIPo6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# genero numeros primos\n",
        "primos <- generate_primes(min = 100000, max = 1000000)\n",
        "set.seed(PARAM$semilla_primigenia) # inicializo\n",
        "# me quedo con PARAM$qsemillas   semillas\n",
        "PARAM$semillas <- sample(primos, PARAM$qsemillas )\n"
      ],
      "metadata": {
        "id": "tSlY0EcgIWdi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# genero la data.table donde van los resultados detallados del Grid Search\n",
        "# un registro para cada combinacion de < semilla, parametros >\n",
        "tb_grid_search_detalle <- NULL\n",
        "\n",
        "verifica_tabla_detalles <- function(filename = \"gridsearch_detalle.txt\") {\n",
        "\n",
        "\tif(file.exists(filename)){\n",
        "\t  tb_grid_search_detalle <- fread(filename)\n",
        "\t}else{\n",
        "\t  tb_grid_search_detalle <- data.table(\n",
        "\t\tsemilla = integer(),\n",
        "\t\tcp = numeric(),\n",
        "\t\tmaxdepth = integer(),\n",
        "\t    minsplit = integer(),\n",
        "\t\tminbucket = integer(),\n",
        "\t\tganancia_test = numeric()\n",
        "\t  )\n",
        "\t}\n",
        "\n",
        "\tnrow( tb_grid_search_detalle )\n",
        "\n",
        "\ttb_grid_search_detalle\n",
        "}"
      ],
      "metadata": {
        "id": "xxCAwIKyIaTl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta es la parte del código que usted debe expandir a TODOS los hiperparámetros de rpart,\n",
        "<br>ya que actualmente apenas recorre  maxdepth y  minsplit  dejando fijos  cp=-0.5  y minbucket=5"
      ],
      "metadata": {
        "id": "eAuGBNL8IkOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "\n",
        "# # itero por los loops anidados para cada hiperparametro\n",
        "# iter <- 0\n",
        "\n",
        "# for (vmax_depth in c(4, 6, 8, 10, 12, 14)) {\n",
        "#   for (vmin_split in c(1000, 800, 600, 400, 200, 100, 50, 20, 10)) {\n",
        "#     # notar como se agrega\n",
        "\n",
        "#     for(vcp in c(-1, -0.7, -0.5, -0.1, 0, 0.2)) {\n",
        "#       for (vmin_bucket in c(5, 10, 20, 50, 100)) {\n",
        "\n",
        "\n",
        "#         iter <- iter + 1\n",
        "#         cat( iter, \" \" )\n",
        "#         flush.console()\n",
        "#         if( iter*PARAM$qsemillas < nrow(tb_grid_search_detalle)+1 ) next\n",
        "\n",
        "#         # vminsplit  minima cantidad de registros en un nodo para hacer el split\n",
        "#         param_basicos <- list(\n",
        "#           #\"cp\" = -0.5, # complejidad minima\n",
        "#           \"cp\" = vcp, # complejidad minima\n",
        "#           \"maxdepth\" = vmax_depth, # profundidad máxima del arbol\n",
        "#           \"minsplit\" = vmin_split, # tamaño minimo de nodo para hacer split\n",
        "#           #\"minbucket\" = 5 # minima cantidad de registros en una hoja\n",
        "#           \"minbucket\" = vmin_bucket # minima cantidad de registros en una hoja\n",
        "#         )\n",
        "\n",
        "#         # Un solo llamado, con la semilla 17\n",
        "#         ganancias <- ArbolesMontecarlo(PARAM$semillas, param_basicos)\n",
        "\n",
        "#         # agrego a la tabla\n",
        "#         tb_grid_search_detalle <- rbindlist(\n",
        "#           list( tb_grid_search_detalle,\n",
        "#                 rbindlist(ganancias) )\n",
        "#         )\n",
        "#       }\n",
        "#     }\n",
        "\n",
        "#   }\n",
        "\n",
        "#   # grabo cada vez TODA la tabla en el loop mas externo\n",
        "#   fwrite( tb_grid_search_detalle,\n",
        "#           file = \"gridsearch_detalle.txt\",\n",
        "#           sep = \"\\t\" )\n",
        "# }\n"
      ],
      "metadata": {
        "id": "ipLHm3STIfmb",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# ## CAMBIO estrategia de busqueda GridSearch\n",
        "# ## Primero por cp , max_depth\n",
        "# ## Luego por min_split / min_bucket\n",
        "\n",
        "# # Genera vector con valores cp en una escala logaritmic\n",
        "# from_cp <- 0.01\n",
        "# to_cp <- 0.9\n",
        "# num_cp <- 20\n",
        "\n",
        "# cp_seq <- exp(\n",
        "#   seq( log(from_val), log(to_val), length.out = num_points )\n",
        "# ) * -1\n",
        "\n",
        "\n",
        "# #min split en 0.5 y 2% del tamano del dataset de train\n",
        "# dataset_train_len = round(nrow(dataset) * (PARAM$training_pct/ 100))\n",
        "# vmin_split_seq <- c( round(dataset_train_len  * 0.02), round(dataset_train_len  * 0.005) )\n",
        "\n",
        "# # itero por los loops anidados para cada hiperparametro\n",
        "# iter <- 0\n",
        "\n",
        "# #for (vmax_depth in c(4, 6, 8, 10, 12, 14)) {\n",
        "#   #for (vmin_split in c(1000, 800, 600, 400, 200, 100, 50, 20, 10)) {\n",
        "\n",
        "# for (vcp in cp_seq) {\n",
        "#   for (vmax_depth in c(4, 6, 8, 10, 12, 14, 15, 16)) {\n",
        "#     for (vmin_split in vmin_split_seq) {\n",
        "#       iter <- iter + 1\n",
        "#       cat( iter, \" \" )\n",
        "#       flush.console()\n",
        "#       if( iter*PARAM$qsemillas < nrow(tb_grid_search_detalle)+1 ) next\n",
        "\n",
        "#       # vminsplit  minima cantidad de registros en un nodo para hacer el split\n",
        "#       param_basicos <- list(\n",
        "#         \"cp\" = vcp, # complejidad minima\n",
        "#         \"maxdepth\" = vmax_depth, # profundidad máxima del arbol\n",
        "#         \"minsplit\" = vmin_split, # tamaño minimo de nodo para hacer split\n",
        "#         \"minbucket\" = round(vmin_split/3) # minima cantidad de registros en una hoja\n",
        "#       )\n",
        "\n",
        "#       # Un solo llamado, con la semilla 17\n",
        "#       ganancias <- ArbolesMontecarlo(PARAM$semillas, param_basicos)\n",
        "\n",
        "#       # agrego a la tabla\n",
        "#       tb_grid_search_detalle <- rbindlist(\n",
        "#         list( tb_grid_search_detalle,\n",
        "#               rbindlist(ganancias) )\n",
        "#       )\n",
        "\n",
        "#     }\n",
        "\n",
        "#   }\n",
        "\n",
        "#   # grabo cada vez TODA la tabla en el loop mas externo\n",
        "#   fwrite( tb_grid_search_detalle,\n",
        "#           file = \"gridsearch_detalle.txt\",\n",
        "#           sep = \"\\t\" )\n",
        "# }"
      ],
      "metadata": {
        "id": "aK59cRaksScD",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "## CAMBIO estrategia de busqueda GridSearch\n",
        "## en base a analisis anteriores ..\n",
        "## dejo cp en -0.5\n",
        "## max_depth de 8 a 10\n",
        "## min_split entre 500 y 1100, en pasos de 50\n",
        "## min_bucket\n",
        "\n",
        "\n",
        "# maxdepth_seq <- c(8,9,10)\n",
        "# minsplit_seq <- seq(500, 1100, 50)\n",
        "# minbucket_seq <- seq(5, 30, 5)\n",
        "\n",
        "# maxdepth_seq <- c(9,10,11)\n",
        "# minsplit_seq <- seq(700, 1100, 25)\n",
        "# minbucket_seq <- seq(20, 40, 2)\n",
        "\n",
        "# maxdepth_seq <- c(10)\n",
        "# minsplit_seq <- seq(750, 780, 1)\n",
        "# minbucket_seq <- seq(40, 42)\n",
        "\n",
        "# dataset_train_len = round(nrow(dataset) * (PARAM$training_pct/ 100))\n",
        "\n",
        "# # itero por los loops anidados para cada hiperparametro\n",
        "# iter <- 0\n",
        "\n",
        "# vcp <- -0.5\n",
        "\n",
        "# for (vmax_depth in maxdepth_seq) {\n",
        "#   for (vmin_split in minsplit_seq) {\n",
        "#     for (vmin_bucket in minbucket_seq) {\n",
        "\n",
        "#       iter <- iter + 1\n",
        "#       cat( iter, \" \" )\n",
        "#       flush.console()\n",
        "#       if( iter*PARAM$qsemillas < nrow(tb_grid_search_detalle)+1 ) next\n",
        "\n",
        "#       # vminsplit  minima cantidad de registros en un nodo para hacer el split\n",
        "#       param_basicos <- list(\n",
        "#         \"cp\" = vcp, # complejidad minima\n",
        "#         \"maxdepth\" = vmax_depth, # profundidad máxima del arbol\n",
        "#         \"minsplit\" = vmin_split, # tamaño minimo de nodo para hacer split\n",
        "#         \"minbucket\" = vmin_bucket # minima cantidad de registros en una hoja\n",
        "#       )\n",
        "\n",
        "#       # Un solo llamado, con la semilla 17\n",
        "#       ganancias <- ArbolesMontecarlo(PARAM$semillas, param_basicos)\n",
        "\n",
        "#       # agrego a la tabla\n",
        "#       tb_grid_search_detalle <- rbindlist(\n",
        "#         list( tb_grid_search_detalle,\n",
        "#               rbindlist(ganancias) )\n",
        "#       )\n",
        "\n",
        "#     }\n",
        "#     fwrite( tb_grid_search_detalle,\n",
        "#           file = \"gridsearch_detalle.txt\",\n",
        "#           sep = \"\\t\" )\n",
        "\n",
        "#   }\n",
        "#   # grabo cada vez TODA la tabla en el loop mas externo\n",
        "#   fwrite( tb_grid_search_detalle,\n",
        "#           file = \"gridsearch_detalle.txt\",\n",
        "#           sep = \"\\t\" )\n",
        "# }"
      ],
      "metadata": {
        "id": "U__C8pfPeTOW",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "#\n",
        "# Intento nuevamente, dos cp\n",
        "#\n",
        "\n",
        "# itero por los loops anidados para cada hiperparametro\n",
        "# iter <- 0\n",
        "\n",
        "# for (vmax_depth in c(4, 5, 6, 7, 8, 10, 12, 14)) {\n",
        "#   for (vmin_split in seq(10, 1000, 50)) {\n",
        "\n",
        "#     for(vcp in c(-1, -0.5)) {\n",
        "#       for (vmin_bucket in c(round(vmin_split/2), round(vmin_split/2), round(vmin_split/2), round(vmin_split/10))) {\n",
        "\n",
        "\n",
        "#         iter <- iter + 1\n",
        "#         cat( iter, \" \" )\n",
        "#         flush.console()\n",
        "#         if( iter*PARAM$qsemillas < nrow(tb_grid_search_detalle)+1 ) next\n",
        "\n",
        "#         # vminsplit  minima cantidad de registros en un nodo para hacer el split\n",
        "#         param_basicos <- list(\n",
        "#           \"cp\" = vcp, # complejidad minima\n",
        "#           \"maxdepth\" = vmax_depth, # profundidad máxima del arbol\n",
        "#           \"minsplit\" = vmin_split, # tamaño minimo de nodo para hacer split\n",
        "#           \"minbucket\" = vmin_bucket # minima cantidad de registros en una hoja\n",
        "#         )\n",
        "\n",
        "#         # Un solo llamado, con la semilla 17\n",
        "#         ganancias <- ArbolesMontecarlo(PARAM$semillas, param_basicos)\n",
        "\n",
        "#         # agrego a la tabla\n",
        "#         tb_grid_search_detalle <- rbindlist(\n",
        "#           list( tb_grid_search_detalle,\n",
        "#                 rbindlist(ganancias) )\n",
        "#         )\n",
        "\n",
        "#         fwrite( tb_grid_search_detalle,\n",
        "#         file = \"gridsearch_detalle.txt\",\n",
        "#         sep = \"\\t\" )\n",
        "#       }\n",
        "#     }\n",
        "\n",
        "#   }\n",
        "\n",
        "#   # grabo cada vez TODA la tabla en el loop mas externo\n",
        "#   fwrite( tb_grid_search_detalle,\n",
        "#           file = \"gridsearch_detalle.txt\",\n",
        "#           sep = \"\\t\" )\n",
        "# }"
      ],
      "metadata": {
        "id": "nMktXlxcue0z",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Arma Lista de parametros a evaluar\n",
        "\n",
        "param_search <- list()\n",
        "param_i <- 1\n",
        "for (vmax_depth in c(4, 5, 6, 7, 8, 10, 12, 14)) {\n",
        "  for (vmin_split in seq(10, 1000, 50)) {\n",
        "    for(vcp in c(-1)) {\n",
        "      for (vmin_bucket in c(round(vmin_split/2), round(vmin_split/4), round(vmin_split/8), round(vmin_split/10))) {\n",
        "        param_search[[param_i]] <- list(\n",
        "          cp=vcp,\n",
        "          maxdepth=vmax_depth,\n",
        "          minsplit=vmin_split,\n",
        "          minbucket=vmin_bucket)\n",
        "        param_i <- param_i + 1\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "## Divide la Lista para correr en paralelo en varios Colab\n",
        "\n",
        "param_search_n_splits <- 3\n",
        "\n",
        "param_search_splits <- split(param_search,\n",
        "            f = cut(seq_along(param_search), param_search_n_splits, labels=FALSE)\n",
        "      )\n",
        "\n",
        "\n",
        "## Selecionamos SPLIT PARA CORRER EN ESTE COLAB\n",
        "\n",
        "PARAM_SEARCH_SPLIT <- 3\n",
        "\n",
        "\n",
        "## Corremos entrenamiento en el split seleccionado\n",
        "\n",
        "param_search <- param_search_splits[[PARAM_SEARCH_SPLIT]]\n",
        "\n",
        "cat(\"Split Number: \", PARAM_SEARCH_SPLIT, \"\\n\")\n",
        "cat(\"Split Size: \", length(param_search), \"\\n\")\n",
        "\n",
        "param_filename <- sprintf(\"gridsearch_detalle_%02d.txt\", PARAM_SEARCH_SPLIT)\n",
        "\n",
        "tb_grid_search_detalle <- verifica_tabla_detalles(param_filename)\n",
        "\n",
        "iter <- 0\n",
        "\n",
        "for (params in param_search)\n",
        "{\n",
        "\n",
        "\n",
        "  iter <- iter + 1\n",
        "  cat( iter, \" \" )\n",
        "  flush.console()\n",
        "\n",
        "  if( iter*PARAM$qsemillas < nrow(tb_grid_search_detalle)+1 ) next\n",
        "\n",
        "  # vminsplit  minima cantidad de registros en un nodo para hacer el split\n",
        "  param_basicos <- list(\n",
        "    \"cp\" = params$cp, # complejidad minima\n",
        "    \"maxdepth\" = params$maxdepth, # profundidad máxima del arbol\n",
        "    \"minsplit\" = params$minsplit, # tamaño minimo de nodo para hacer split\n",
        "    \"minbucket\" = params$minbucket # minima cantidad de registros en una hoja\n",
        "  )\n",
        "\n",
        "  # Un solo llamado, con la semilla 17\n",
        "  ganancias <- ArbolesMontecarlo(PARAM$semillas, param_basicos)\n",
        "\n",
        "  # agrego a la tabla\n",
        "  tb_grid_search_detalle <- rbindlist(\n",
        "    list( tb_grid_search_detalle,\n",
        "          rbindlist(ganancias) )\n",
        "  )\n",
        "\n",
        "  fwrite( tb_grid_search_detalle,\n",
        "          file = param_filename,\n",
        "          sep = \"\\t\" )\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "gz01YiGpB31E",
        "outputId": "f6652aff-3063-4efb-99ad-e5bf4521d408",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split Number:  1 \n",
            "Split Size:  214 \n",
            "1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99  100  101  102  103  104  105  106  107  108  109  110  111  112  113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128  129  130  131  132  133  134  135  136  137  138  139  140  141  142  143  144  145  146  147  148  149  150  151  152  153  154  155  156  157  158  159  160  161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  176  177  178  179  180  181  182  183  184  185  186  187  188  189  190  191  192  193  194  195  196  197  198  199  200  201  202  203  204  205  206  207  208  209  210  211  212  213  214  "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fwrite( tb_grid_search_detalle,\n",
        "   file = \"gridsearch_detalle.txt\",\n",
        "   sep = \"\\t\"\n",
        ")"
      ],
      "metadata": {
        "id": "WZaSqYBxiDFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cantidad de registros de la tabla\n",
        "nrow(tb_grid_search_detalle)"
      ],
      "metadata": {
        "id": "STp0duM-RYVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# muestro la tabla\n",
        "tb_grid_search_detalle"
      ],
      "metadata": {
        "id": "k7fhk_H0iNez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# genero y grabo el resumen\n",
        "tb_grid_search <- tb_grid_search_detalle[,\n",
        "  list( \"ganancia_mean\" = mean(ganancia_test),\n",
        "    \"qty\" = .N ),\n",
        "  list( cp, maxdepth, minsplit, minbucket )\n",
        "]\n"
      ],
      "metadata": {
        "id": "DjCxtx8bIsgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ordeno descendente por ganancia\n",
        "setorder( tb_grid_search, -ganancia_mean )\n"
      ],
      "metadata": {
        "id": "LU29UhL1Ivg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# veo los 10 mejores hiperparámetros\n",
        "tb_grid_search[1:10]"
      ],
      "metadata": {
        "id": "g-EjGY7aIyWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# genero un id a la tabla\n",
        "tb_grid_search[, id := .I ]\n",
        "\n",
        "fwrite( tb_grid_search,\n",
        "  file = \"gridsearch.txt\",\n",
        "  sep = \"\\t\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "K3S-I2PTI5ZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.  Análisis de resultados de Grid Search"
      ],
      "metadata": {
        "id": "1rYHk1YkI_9k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La salida de la corrida anterior queda en ~/buckets/b1/exp/HT2900  que corresponde a su Google Drive\n",
        "<br>HT significa Hyperparameter Tuning\n",
        "<br>El Grid Search es un método de fuerza bruta de un altísimo costo computacional.\n",
        "<br>Queremos ver si es posible crear un algoritmo de optimización de hiperparámetros que se ahorre recorrer ciertas porciones muy malas del espacio de búsqueda. Algo del estilo “cada vez que pruebo una combinación de hiperparámetros donde  cp > 1 , la ganancia es muy mala, con lo cual ni vale la pena perder el tiempo explorando en esa region”\n"
      ],
      "metadata": {
        "id": "ZTJgPhMWJHTk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>Levante el archivo de salida gridsearch.txt  a una planilla tipo Excel y analícelo detenidamente\n",
        "<br>Ordene por ganancia_mean descendente\n",
        "<br>\n",
        "<br>El de mayor ganancia_mean  decimos que es el primero del ranking\n",
        "En Zulip, correspondiente channel  #Tarea Hogar 02 , topic Analisis Grid Search   intente contestar estas preguntas:\n",
        "\n",
        "* ¿Qué combinaciones de hiperparámetros poseen una ganancia muy buena?\n",
        "* ¿Hay algun hiperparámetro que para cierto valor siempre genera una ganancia muy mala, a independientemente de lo que valgan los otros hiperparámetros ?\n",
        "* ¿Que combinaciones de hiperparámetros es pésima y hubiera sido bueno ahorrarse esas corridas ?\n",
        "\n",
        "( tiempo estimado 30 minutos, dificultad media )"
      ],
      "metadata": {
        "id": "IaVgMu4tPwyB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "ijvKKeKNJUQ-"
      }
    }
  ]
}